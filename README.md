# üìä Customer Churn Prediction

Este proyecto tiene como objetivo **predecir la cancelaci√≥n de clientes (Churn)** en una empresa de telecomunicaciones utilizando **Machine Learning**.  
Se explora, procesa y modela el dataset para identificar los factores m√°s relevantes que influyen en la decisi√≥n de un cliente de abandonar el servicio.

---

## üìÇ Contenido del Proyecto

- **EDA (Exploratory Data Analysis)**  
  - An√°lisis de correlaciones.  
  - Relaci√≥n de variables clave con la cancelaci√≥n (tenure, total charges, contract type, etc.).  
  - Visualizaciones (boxplots, scatterplots, heatmaps).

- **Preprocesamiento de Datos**  
  - Codificaci√≥n de variables categ√≥ricas con `get_dummies()`.  
  - Revisi√≥n y tratamiento de valores nulos.  
  - Divisi√≥n en conjuntos de entrenamiento y prueba.  
  - (Opcional) Balanceo de clases con t√©cnicas como SMOTE.

- **Modelos de Machine Learning**  
  - **Regresi√≥n Log√≠stica** (modelo interpretable y sensible a escala).  
  - **Random Forest** (modelo robusto, no sensible a escala).  

- **Evaluaci√≥n de Modelos**  
  - M√©tricas utilizadas: Accuracy, Precision, Recall, F1-score y ROC-AUC.  
  - Comparaci√≥n entre modelos para seleccionar el m√°s adecuado.

---

## ‚öôÔ∏è Tecnolog√≠as Utilizadas

- **Python 3**  
- Librer√≠as principales:  
  - `pandas`, `numpy` ‚Üí Manipulaci√≥n de datos.  
  - `matplotlib`, `seaborn` ‚Üí Visualizaci√≥n.  
  - `scikit-learn` ‚Üí Modelado y m√©tricas.

---

## üìà Resultados

- **Random Forest**  
  - Accuracy: 0.75  
  - Recall (churners): 0.50  
  - ROC-AUC: 0.79  

- **Regresi√≥n Log√≠stica**  
  - Accuracy: 0.78  
  - Recall (churners): 0.57  
  - ROC-AUC: 0.82  

üëâ La **Regresi√≥n Log√≠stica result√≥ ser el mejor modelo base**, ya que logra un mejor balance entre precisi√≥n y recall, adem√°s de un ROC-AUC superior.  

---

## ‚úÖ Conclusiones

- Existe un **desbalance en las clases** (mayor√≠a de clientes no cancelan).  
- La **Regresi√≥n Log√≠stica** es preferible como modelo inicial por su mejor desempe√±o en la detecci√≥n de clientes con riesgo de cancelar.  
- Futuras mejoras:  
  1. Aplicar balanceo de clases (SMOTE, oversampling).  
  2. Optimizar hiperpar√°metros en Random Forest y probar con **XGBoost**.  
  3. Crear nuevas variables derivadas (feature engineering).

---
